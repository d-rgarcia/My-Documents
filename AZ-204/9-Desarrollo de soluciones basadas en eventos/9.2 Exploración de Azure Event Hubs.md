## Información sobre Azure Event Hubs

Azure Event Hubs representa la "puerta principal" de una canalización de eventos, a menudo denominada agente de ingesta de eventos en las arquitecturas de soluciones. Un agente de ingesta de eventos es un componente o servicio que se encuentra entre los publicadores de eventos y los consumidores de eventos para desacoplar la producción de un flujo de eventos del consumo de esos eventos. Event Hubs ofrece una plataforma de streaming unificada con búfer de retención de tiempo, de forma que los productores de eventos se desacoplan de los consumidores de eventos.

En la tabla siguiente se resaltan las características clave del servicio Azure Event Hubs:

- PaaS completamente administrada: Event Hubs es una plataforma como servicio (PaaS) completamente administrada con poca sobrecarga de administración o configuración, para que pueda centrarse en las soluciones empresariales. Event Hubs para ecosistemas de Apache Kafka le ofrece la experiencia de PaaS de Kafka sin tener que administrar, configurar ni ejecutar los clústeres.

- Procesamiento por lotes y en tiempo real: Event Hubs usa un modelo de consumidor con particiones, que permite que varias aplicaciones procesen la secuencia de manera simultánea y le deja controlar la velocidad del procesamiento.

- Escalable: Las opciones de escalado, como el inflado automático, escalan el número de unidades de procesamiento para satisfacer sus necesidades de uso.

- Ecosistema enriquecido: Event Hubs para ecosistemas de Apache Kafka permite que aplicaciones y clientes de Apache Kafka (1.0 y posteriores) se comuniquen con Event Hubs. No es necesario configurar ni administrar sus propios clústeres de Kafka.

### Conceptos clave

- Un cliente de centros de eventos es la interfaz principal para los desarrolladores que interactúan con la biblioteca cliente de Event Hubs. Hay varios clientes de Event Hubs diferentes, cada uno dedicado a un uso específico de Event Hubs, como la publicación o el consumo de eventos.

- Un productor de centros de eventos es un tipo de cliente que actúa como origen de datos de telemetría, información de diagnóstico, registros de uso u otros datos de registro, como parte de una solución de dispositivo insertada, una aplicación de dispositivo móvil, un título de juego que se ejecuta en una consola u otro dispositivo, alguna solución empresarial basada en cliente o servidor o un sitio web.

- Un consumidor de centros de eventos es un tipo de cliente que lee información del centro de eventos y permite su procesamiento. El procesamiento puede implicar agregación, cálculo complejo y filtrado. El procesamiento también puede implicar la distribución o el almacenamiento de la información sin procesar o transformada. Los consumidores de centros de eventos suelen ser componentes sólidos y a gran escala de la infraestructura de la plataforma con funcionalidades de análisis integradas, como Azure Stream Analytics, Apache Spark o Apache Storm.

- Una partición es una secuencia ordenada de eventos que se mantiene en un centro de eventos. Las particiones son un medio de organización de datos asociado al paralelismo requerido por los consumidores de eventos. Azure Event Hubs proporciona streaming de mensajes a través de un patrón de consumidor con particiones en el que cada consumidor solo lee un subconjunto específico, o partición, de la secuencia de mensajes. A medida que llegan eventos más recientes, se agregan al final de esta secuencia. El número de particiones se especifica en el momento en que se crea un centro de eventos y no se puede modificar.

- Un grupo de consumidores es una vista de un centro de eventos completo. Los grupos de consumidores habilitan a varias aplicaciones de consumo para que cada una de ellas tenga una vista independiente de la secuencia de eventos, y para que lea la secuencia de manera independiente a su propio ritmo y desde su propia ubicación. Puede haber como máximo cinco lectores simultáneos en una partición por grupo de consumidores; sin embargo, se recomienda que solo haya un consumidor activo para un emparejamiento determinado de partición y grupo de consumidores. Cada lector activo recibe todos los eventos de su partición; si hay varios lectores en la misma partición, recibirán eventos duplicados.

- Receptores de eventos: cualquier entidad que lea datos de evento de un centro de eventos. Todos los consumidores de Event Hubs se conectan a través de la sesión de AMQP 1.0. El servicio Event Hubs entrega eventos a través de una sesión a medida que están disponibles. Todos los consumidores de Kafka se conectan a través del protocolo de 1.0 de Kafka y las versiones posteriores.

- Unidades de rendimiento o unidades de procesamiento: unidades de capacidad compradas previamente que controlan la capacidad de rendimiento de Event Hubs

## Exploración de Event Hubs Capture

Azure Event Hubs permite capturar automáticamente los datos de streaming de Event Hubs de la cuenta de Azure Blob Storage o Azure Data Lake Storage que prefiera, con la flexibilidad agregada de poder especificar un intervalo de tiempo o de tamaño. La configuración de Capture es rápida, su ejecución no conlleva ningún gasto administrativo y se escala automáticamente con unidades de rendimiento de Event Hubs en el nivel estándar o unidades de procesamiento en el nivel Premium.

Event Hubs Capture permite procesar las canalizaciones en tiempo real y las basadas en lotes en la misma transmisión, lo que permite crear soluciones que crecen a la par que sus necesidades.

### Funcionamiento de Event Hubs Capture

Event Hubs es un búfer duradero de retención temporal para la entrada de datos de telemetría, es similar a un registro distribuido. La clave para reducir horizontalmente en Event Hubs es el modelo de consumidor con particiones. Cada partición es un segmento de datos independiente y se consume de forma independiente. Con el tiempo estos datos envejecen basándose en el período de retención configurable. Como consecuencia, un centro de eventos determinado nunca llega a estar "demasiado lleno".

Event Hubs Capture le permite especificar su propia cuenta y contenedor de Azure Blob Storage, o cuenta de Azure Data Lake Store, que se usan para almacenar los datos capturados. Estas cuentas pueden estar en la misma región que el centro de eventos o en otra, lo que se suma a la flexibilidad de la característica Event Hubs Capture.

Los datos capturados se escriben en el formato de Apache Avro, que es un formato compacto, rápido y binario que proporciona estructuras de datos enriquecidos con un esquema insertado. Este formato se usa ampliamente en el ecosistema de Hadoop, en Stream Analytics y en Azure Data Factory. En este mismo artículo encontrará más información acerca de cómo trabajar con Avro.

### Ventanas de captura

Event Hubs Capture permite configurar una ventana para controlar la captura. Esta ventana es una configuración mínima de tamaño y tiempo con una "directiva de que el primero gana", lo que significa que el primer desencadenador que se encuentre provocará una operación de captura. Cada partición se captura de forma independiente y escribe un blob en bloques completado en el momento de la captura, denominado como la hora en que se encontró el intervalo de captura. Esta es la convención de nomenclatura de almacenamiento:

{Namespace}/{EventHub}/{PartitionId}/{Year}/{Month}/{Day}/{Hour}/{Minute}/{Second}

Tenga en cuenta que los valores de fecha se rellenan con ceros; un nombre de archivo de ejemplo podría ser:

https://mystorageaccount.blob.core.windows.net/mycontainer/mynamespace/myeventhub/0/2017/12/08/03/03/17.avro

### Escalado a unidades de procesamiento

El tráfico de Event Hubs lo controlan las unidades de procesamiento. Una sola unidad de procesamiento permite una entrada de 1 MB/s o 1000 eventos por segundo y una salida que duplica esas cifras. Event Hubs estándar se puede configurar con entre 1 y 20 unidades de procesamiento, y puede adquirir más a través de una solicitud de aumento de cuota al equipo de soporte técnico. El uso por encima de las unidades de procesamiento adquiridas está limitado. Event Hubs Capture copia los datos directamente del almacenamiento interno de Event Hubs, omite las cuotas de salida de unidades de procesamiento y guarda la salida para otros lectores de procesamiento como Stream Analytics o Spark.

Una vez configurado, Event Hubs Capture se ejecuta automáticamente cuando se envía el primer evento y continúa ejecutándose. Para facilitar que el procesamiento de bajada sepa que el proceso funciona, Event Hubs escribe archivos vacíos cuando no hay datos. Este proceso proporciona un marcador y una cadencia predecibles que puede alimentar sus procesadores de lotes.

## Escalado de la aplicación de procesamiento

Para escalar la aplicación de procesamiento de eventos, puede ejecutar varias instancias de la aplicación y equilibrar la carga entre ellas. En las versiones anteriores, EventProcessorHost permitía equilibrar la carga entre varias instancias del programa y eventos de punto de comprobación en la recepción. En las versiones más recientes (5.0 y posteriores), EventProcessorClient (.NET y Java) o EventHubConsumerClient (Python y JavaScript) le permiten hacer lo mismo.

La clave del escalado de Event Hubs es el concepto de consumidores con particiones. En contraposición al patrón de consumidores de la competencia, el patrón de consumidores con particiones permite una alta escalabilidad mediante la eliminación de cuellos de botella de contención y la facilitación del paralelismo de principio a fin.

### Escenario de ejemplo

Como caso de ejemplo, considere una empresa de seguridad en el hogar que supervisa 100 000 casas. Cada minuto, obtiene los datos de los diversos sensores como el detector de movimiento, el sensor de apertura de puertas y ventanas, el detector de rotura de cristales, etc., instalados en cada casa. La empresa proporciona un sitio web para que los residentes supervisen la actividad de su casa casi en tiempo real.

Cada sensor inserta datos en un centro de eventos. El centro de eventos está configurado con 16 particiones. En el extremo de consumo, necesita un mecanismo que pueda leer estos eventos, consolidarlos y volcar el agregado en un blob de almacenamiento, que luego se proyecta en una página web fácil de usar.

Al diseñar el consumidor en un entorno distribuido, el escenario debe controlar los siguientes requisitos:

- Escalado: cree varios consumidores y que cada consumidor tome posesión de la lectura desde varias particiones de Event Hubs.

- Equilibrio de carga: aumente o reduzca dinámicamente los consumidores. Por ejemplo, si se agrega un nuevo tipo de sensor (por ejemplo, un detector de monóxido de carbono) a cada casa, aumenta el número de eventos. En ese caso, el operador (una persona) aumenta el número de instancias de consumidor. A continuación, el grupo de consumidores puede volver a equilibrar el número de particiones que poseen para compartir la carga con los consumidores recién agregados.

- Reanudación sin problemas después de los errores: si un consumidor (consumidor A) genera un error (por ejemplo, la máquina virtual que hospeda al consumidor se bloquea de repente), otros consumidores pueden recopilar las particiones que posee el consumidor A y continuar. Además, el punto de continuación, llamado punto de comprobación o de desplazamiento, debe estar en el punto exacto en el que se produjo el error del consumidor A o ligeramente antes.

- Consumo de eventos: mientras que los tres puntos anteriores trataban sobre la administración del consumidor, también tiene que haber código para consumir los eventos y hacer algo útil con él. Por ejemplo, agréguelo y cárguelo en el almacenamiento de blobs.

### Cliente de consumidor o procesador de eventos

No es necesario que cree su propia solución para cumplir estos requisitos. Los SDK de Azure Event Hubs proporcionan esta funcionalidad. En los SDK de .NET o Java, se usa un cliente de procesador de eventos (EventProcessorClient) y, en los SDK de Python y JavaScript, se usa EventHubConsumerClient.

En la mayoría de los escenarios de producción, se recomienda usar el cliente del procesador de eventos para leer y procesar eventos. Los clientes del procesador de eventos pueden trabajar en colaboración en el contexto de un grupo de consumidores para un centro de eventos determinado. Los clientes administrarán de forma automática la distribución y el equilibrio del trabajo a medida que las instancias estén disponibles o no para el grupo.

### Seguimiento de la propiedad de una partición

Por lo general, una instancia de procesador de eventos posee y procesa los eventos de una o de varias particiones. La propiedad de las particiones se distribuye uniformemente entre todas las instancias del procesador de eventos activas asociadas a una combinación de centro de eventos y grupo de consumidores.

Cada procesador de eventos recibe un identificador único y notifica la propiedad de las particiones mediante la adición o actualización de una entrada en un almacén de puntos de control. Todas las instancias del procesador de eventos se comunican con este almacén periódicamente para actualizar su propio estado de procesamiento, así como para obtener información sobre otras instancias activas. Después, estos datos se usan para equilibrar la carga entre los procesadores activos.

### Recepción de mensajes

Cuando se crea un procesador de eventos, se especifican las funciones que van a procesar los eventos y los errores. Cada llamada a la función que procesa los eventos entrega un solo evento de una partición específica. Es su responsabilidad administrar este evento. Si desea asegurarse de que el consumidor procesa cada mensaje al menos una vez, debe escribir su propio código con lógica de reintento. Pero tenga cuidado con los mensajes dudosos.

Se recomienda que lo haga relativamente rápido. Es decir, use el menor procesamiento posible. Si tiene que escribir en el almacenamiento y llevar a cabo cierto enrutamiento, es mejor usar dos grupos de consumidores y tener dos procesadores de eventos.

### Puntos de control

El punto de control es un proceso por el que un procesador de eventos marca o confirma la posición del último evento procesado correctamente en una partición. Por lo general, el marcado de un punto de control se realiza en la función que procesa los eventos y se produce en cada partición de un grupo de consumidores.

Si un procesador de eventos se desconecta de una partición, otra instancia puede reanudar el procesamiento de la partición en el punto de control confirmado previamente por el último procesador de esa partición en ese grupo de consumidores. Cuando se conecta el procesador, pasa el desplazamiento al centro de eventos para especificar la ubicación en la que se va a empezar a leer. De este modo, puede usar puntos de control para que las aplicaciones de nivel inferior marquen los eventos como "completados" y para ofrecer resistencia cuando un procesador de eventos quede fuera de servicio. Es posible volver a los datos más antiguos especificando un desplazamiento inferior desde este proceso de puntos de control.

### Seguridad para subprocesos e instancias de procesador

De forma predeterminada, se llama de forma secuencial a la función que procesa los eventos para una partición determinada. Los siguientes eventos y llamadas a esta función desde la misma partición se ponen en cola en segundo plano mientras el suministro de eventos continúa ejecutándose en segundo plano en otros subprocesos. Los eventos de diferentes particiones se pueden procesar simultáneamente, y cualquier estado compartido al que se tenga acceso desde varias particiones se debe sincronizar.

## Control del acceso a eventos

Azure Event Hubs admite Azure Active Directory y firmas de acceso compartido (SAS) para controlar la autenticación y la autorización. Azure proporciona los siguientes roles integrados de Azure para autorizar el acceso a los datos de Event Hubs mediante Azure Active Directory y OAuth:

- Propietario de datos de Azure Event Hubs: use este rol para otorgar acceso total a los recursos de Event Hubs.

- Remitente de datos de Azure Event Hubs: use este rol para otorgar acceso de envío a los recursos de Event Hubs.

- Destinatario de datos de Azure Event Hubs: use este rol para otorgar acceso de recepción a los recursos de Event Hubs.

### Autorización del acceso con identidades administradas

Para autorizar una solicitud al servicio Event Hubs desde una identidad administrada en la aplicación, debe configurar los valores de control de acceso basado en rol de Azure para esa identidad administrada. Azure Event Hubs define los roles de Azure que abarcan los permisos para enviar y leer desde Event Hubs. Cuando el rol de Azure se asigna a una identidad administrada, a esta se le concede acceso a los datos de Event Hubs en el ámbito adecuado.

### Autorización del acceso con la Plataforma de identidad de Microsoft

Una ventaja clave del uso de Azure AD con Event Hubs es que ya no necesita almacenar las credenciales en el código. En su lugar, puede solicitar un token de acceso de OAuth 2.0 desde la Plataforma de identidad de Microsoft. Azure AD autentica la entidad de seguridad (un usuario, grupo o entidad de servicio) ejecutando la aplicación. Si la autenticación se realiza correctamente, Azure AD devuelve el token de acceso a la aplicación y la aplicación puede entonces usar el token de acceso para autorizar las solicitudes de Azure Event Hubs.

### Autorización del acceso a publicadores de Event Hubs con firmas de acceso compartido

Un publicador de eventos define un extremo virtual para un Centro de eventos. El publicador solo puede usarse para enviar mensajes a un centro de eventos, no para recibirlos. Normalmente, un centro de eventos emplea a un publicador por cliente. Todos los mensajes que se envíen a cualquiera de los publicadores de un centro de eventos se ponen en cola dentro de ese centro de eventos. Los publicadores permiten control de acceso pormenorizado.

A cada cliente de Event Hubs se le asigna un token único que se carga en el cliente. Un cliente que posea un token solo puede enviar a un publicador y a ningún otro. Si varios clientes comparten el mismo token, cada uno de estos clientes comparte el publicador.

Todos los tokens se asignan con claves de firma de acceso compartido. Normalmente, todos los tokens se firman con la misma clave. Los clientes no conocen la clave, lo que evita que los clientes produzcan tokens. Los clientes operan en los mismos tokens hasta que expiran.

### Autorización del acceso a consumidores de Event Hubs con firmas de acceso compartido

Para autenticar las aplicaciones back-end que consumen los datos generados por los productores de Event Hubs, la autenticación de tokens de Event Hubs requiere que sus clientes tengan asignados los derechos de administración o los privilegios de escucha a su espacio de nombres de Event Hubs o instancia o tema del centro de eventos. Los datos se consumen de Event Hubs mediante grupos de consumidores. Aunque la directiva SAS proporciona un ámbito granular, este ámbito solo se define en el nivel de entidad, no en el nivel de consumidor. Significa que los privilegios definidos en el nivel de espacio de nombres o en el nivel de instancia o tema de centro de eventos se aplicarán a los grupos de consumidores de esa entidad.

## Realizar operaciones comunes con la biblioteca cliente de Event Hubs

Esta unidad contiene ejemplos de operaciones comunes que puede realizar con la biblioteca cliente de Event Hubs (Azure.Messaging.EventHubs) para interactuar con un centro de eventos.

### Inspección de un centro de eventos

Muchas operaciones del centro de eventos tienen lugar dentro del ámbito de una partición específica. Dado que las particiones son propiedad del centro de eventos, sus nombres se asignan en el momento en que se crean. Para saber qué particiones están disponibles, consulte el centro de eventos mediante uno de los clientes del centro de eventos. A modo de ilustración, se muestra EventHubProducerClient en estos ejemplos, pero el concepto y la forma son comunes entre los clientes.

```c#
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

await using (var producer = new EventHubProducerClient(connectionString, eventHubName))
{
    string[] partitionIds = await producer.GetPartitionIdsAsync();
}
```

### Publicación de eventos en un centro de eventos

Para publicar eventos, deberá crear un elemento EventHubProducerClient. Los productores publican eventos por lotes y pueden solicitar una partición específica o permitir que el servicio Event Hubs decida en qué eventos de partición se deben publicar. Se recomienda usar el enrutamiento automático cuando la publicación de eventos necesite tener una alta disponibilidad o cuando los datos de eventos se deban distribuir entre las particiones de manera uniforme. Nuestro ejemplo utilizará el enrutamiento automático.

```c#
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

await using (var producer = new EventHubProducerClient(connectionString, eventHubName))
{
    using EventDataBatch eventBatch = await producer.CreateBatchAsync();
    eventBatch.TryAdd(new EventData(new BinaryData("First")));
    eventBatch.TryAdd(new EventData(new BinaryData("Second")));

    await producer.SendAsync(eventBatch);
}
```

### Lectura de eventos desde un centro de eventos

Para leer eventos de un centro de eventos, deberá crear un EventHubConsumerClient para un grupo de consumidores determinado. Cuando se crea un centro de eventos, proporciona un grupo de consumidores predeterminado que se puede usar para empezar a explorar Event Hubs. En nuestro ejemplo, nos centraremos en leer todos los eventos publicados en el centro de eventos mediante un iterador.

Para su uso en producción, se recomienda usar el cliente de procesador de eventos, ya que proporciona una experiencia más sólida y mejorada.

```c#
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

string consumerGroup = EventHubConsumerClient.DefaultConsumerGroupName;

await using (var consumer = new EventHubConsumerClient(consumerGroup, connectionString, eventHubName))
{
    using var cancellationSource = new CancellationTokenSource();
    cancellationSource.CancelAfter(TimeSpan.FromSeconds(45));

    await foreach (PartitionEvent receivedEvent in consumer.ReadEventsAsync(cancellationSource.Token))
    {
        // At this point, the loop will wait for events to be available in the Event Hub.  When an event
        // is available, the loop will iterate with the event that was received.  Because we did not
        // specify a maximum wait time, the loop will wait forever unless cancellation is requested using
        // the cancellation token.
    }
}
```

### Lectura de eventos desde una partición de un centro de eventos

Para leer desde una partición específica, el consumidor deberá especificar dónde empezar a recibir eventos en el flujo de eventos; en nuestro ejemplo, nos centraremos en leer todos los eventos publicados para la primera partición del centro de eventos.

```c#
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

string consumerGroup = EventHubConsumerClient.DefaultConsumerGroupName;

await using (var consumer = new EventHubConsumerClient(consumerGroup, connectionString, eventHubName))
{
    EventPosition startingPosition = EventPosition.Earliest;
    string partitionId = (await consumer.GetPartitionIdsAsync()).First();

    using var cancellationSource = new CancellationTokenSource();
    cancellationSource.CancelAfter(TimeSpan.FromSeconds(45));

    await foreach (PartitionEvent receivedEvent in consumer.ReadEventsFromPartitionAsync(partitionId, startingPosition, cancellationSource.Token))
    {
        // At this point, the loop will wait for events to be available in the partition.  When an event
        // is available, the loop will iterate with the event that was received.  Because we did not
        // specify a maximum wait time, the loop will wait forever unless cancellation is requested using
        // the cancellation token.
    }
}
```

### Procesamiento de eventos mediante un cliente de procesador de eventos

En la mayoría de los escenarios de producción, se recomienda utilizar EventProcessorClient para leer y procesar eventos. Dado que EventProcessorClient tiene una dependencia de los blobs de Azure Storage para la persistencia de su estado, deberá proporcionar un BlobContainerClient para el procesador, que se ha configurado para la cuenta de almacenamiento y el contenedor que se deben usar.

```c#
var cancellationSource = new CancellationTokenSource();
cancellationSource.CancelAfter(TimeSpan.FromSeconds(45));

var storageConnectionString = "<< CONNECTION STRING FOR THE STORAGE ACCOUNT >>";
var blobContainerName = "<< NAME OF THE BLOB CONTAINER >>";

var eventHubsConnectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";
var consumerGroup = "<< NAME OF THE EVENT HUB CONSUMER GROUP >>";

Task processEventHandler(ProcessEventArgs eventArgs) => Task.CompletedTask;
Task processErrorHandler(ProcessErrorEventArgs eventArgs) => Task.CompletedTask;

var storageClient = new BlobContainerClient(storageConnectionString, blobContainerName);
var processor = new EventProcessorClient(storageClient, consumerGroup, eventHubsConnectionString, eventHubName);

processor.ProcessEventAsync += processEventHandler;
processor.ProcessErrorAsync += processErrorHandler;

await processor.StartProcessingAsync();

try
{
    // The processor performs its work in the background; block until cancellation
    // to allow processing to take place.

    await Task.Delay(Timeout.Infinite, cancellationSource.Token);
}
catch (TaskCanceledException)
{
    // This is expected when the delay is canceled.
}

try
{
    await processor.StopProcessingAsync();
}
finally
{
    // To prevent leaks, the handlers should be removed when processing is complete.

    processor.ProcessEventAsync -= processEventHandler;
    processor.ProcessErrorAsync -= processErrorHandler;
}
```
